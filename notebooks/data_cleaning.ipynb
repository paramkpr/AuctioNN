{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "We need to clean up these parquet files before we can use them for training the neural network. On a high level, we need to:\n",
    "1. Figure out the linking strategy between impressions and conversions. I.e. which impressions lead to which conversions.\n",
    "2. Ingest the data into a torch dataset.\n",
    "   1. Remove unused or underused columns.\n",
    "   2. Handle missing values\n",
    "   3. Rename columns to be more descriptive.\n",
    "   4. Parse any columns that need to be parsed.(eg. user-agent strings)\n",
    "   5. Finally, think about what feature engineering needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000) # Adjust width for better table display if needed\n",
    "\n",
    "impressions_path = './data/test_dataset/impressions_test.pqt/'\n",
    "conversions_path = './data/test_dataset/conversions_test.pqt/'\n",
    "device_types_path = './data/data_dictionary/device_types.csv'\n",
    "\n",
    "# Load the impressions dataset\n",
    "# Note: Parquet datasets can be stored as directories. Pandas reads them correctly.\n",
    "df_impressions = pd.read_parquet(impressions_path)\n",
    "df_conversions = pd.read_parquet(conversions_path)\n",
    "\n",
    "df_conversions[['imp_click_dttm_utc', 'conv_dttm_utc']].head()\n",
    "\n",
    "df_impressions = df_impressions.drop(columns=[col for col in df_impressions.columns if col.startswith('aip')])\n",
    "df_conversions = df_conversions.drop(columns=[col for col in df_conversions.columns if col.startswith('aip')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify the linking strategy between impressions and conversions.\n",
    "I think the best way to do this is to look at the `imp_click_dttm_utc` and `conv_dttm_utc` columns in conjunction with the `campaign_id`, `placement_id`, and `imp_click_campaign_id`, `imp_click_placement_id` columns. I think that this should be unique, but I'm not sure at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   dte_x                    0 non-null      object        \n",
      " 1   campaign_id              0 non-null      int64         \n",
      " 2   placement_id             0 non-null      int64         \n",
      " 3   dttm_utc                 0 non-null      datetime64[ns]\n",
      " 4   cnxn_type                0 non-null      object        \n",
      " 5   user_agent               0 non-null      object        \n",
      " 6   dma                      0 non-null      int32         \n",
      " 7   country                  0 non-null      object        \n",
      " 8   os                       0 non-null      object        \n",
      " 9   prizm_premier_code       0 non-null      object        \n",
      " 10  device_type              0 non-null      object        \n",
      " 11  dttm_utc_sec             0 non-null      datetime64[ns]\n",
      " 12  dte_y                    0 non-null      object        \n",
      " 13  conv_dttm_utc            0 non-null      datetime64[ns]\n",
      " 14  imp_click_dttm_utc       0 non-null      datetime64[ns]\n",
      " 15  imp_click_campaign_id    0 non-null      int64         \n",
      " 16  imp_click_placement_id   0 non-null      int64         \n",
      " 17  conv_property_id         0 non-null      int64         \n",
      " 18  conv_dma                 0 non-null      int32         \n",
      " 19  conv_user_agent          0 non-null      object        \n",
      " 20  goal_id                  0 non-null      int64         \n",
      " 21  goal_name                0 non-null      object        \n",
      " 22  conv_prizm_premier_code  0 non-null      object        \n",
      " 23  conv_cnxn_type           0 non-null      object        \n",
      " 24  conv_device_type         0 non-null      object        \n",
      " 25  imp_click_dttm_utc_sec   0 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](5), int32(2), int64(6), object(13)\n",
      "memory usage: 132.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# deal with timestamp precision\n",
    "df_impressions['dttm_utc_sec'] = df_impressions['dttm_utc'].dt.round('s')\n",
    "df_conversions['imp_click_dttm_utc_sec'] = df_conversions['imp_click_dttm_utc'].dt.round('s')\n",
    "\n",
    "# perform a left join on impressions and conversions\n",
    "df_merged_correct = pd.merge(\n",
    "        df_impressions,\n",
    "        df_conversions,\n",
    "        left_on=['dttm_utc', 'campaign_id', 'placement_id'],\n",
    "        right_on=['imp_click_dttm_utc', 'imp_click_campaign_id', 'imp_click_placement_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "df_merged_correct.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique (Campaign, Placement) pairs in Impressions: 2\n",
      "    campaign_id  placement_id\n",
      "0          9317        596772\n",
      "31         9317        596771\n",
      "\n",
      "Unique (Campaign, Placement) pairs attributed in Conversions: 2\n",
      "    imp_click_campaign_id  imp_click_placement_id\n",
      "0                    9317                  596772\n",
      "12                   9317                  596771\n",
      "\n",
      "Number of overlapping ID pairs found: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>placement_id</th>\n",
       "      <th>imp_click_campaign_id</th>\n",
       "      <th>imp_click_placement_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9317</td>\n",
       "      <td>596771</td>\n",
       "      <td>9317</td>\n",
       "      <td>596771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id  placement_id  imp_click_campaign_id  imp_click_placement_id\n",
       "0         9317        596772                   9317                  596772\n",
       "1         9317        596771                   9317                  596771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get unique Campaign/Placement ID pairs from impressions\n",
    "imp_ids = df_impressions[['campaign_id', 'placement_id']].drop_duplicates()\n",
    "print(f\"Unique (Campaign, Placement) pairs in Impressions: {len(imp_ids)}\")\n",
    "print(imp_ids.head())\n",
    "\n",
    "# Get unique Campaign/Placement ID pairs from conversions (using the attribution columns)\n",
    "conv_ids = df_conversions[['imp_click_campaign_id', 'imp_click_placement_id']].drop_duplicates()\n",
    "print(f\"\\nUnique (Campaign, Placement) pairs attributed in Conversions: {len(conv_ids)}\")\n",
    "print(conv_ids.head())\n",
    "\n",
    "# Perform an INNER merge *only* on these IDs to see if there's *any* overlap\n",
    "df_id_overlap = pd.merge(\n",
    "    imp_ids,\n",
    "    conv_ids,\n",
    "    left_on=['campaign_id', 'placement_id'],\n",
    "    right_on=['imp_click_campaign_id', 'imp_click_placement_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\nNumber of overlapping ID pairs found: {len(df_id_overlap)}\")\n",
    "display(df_id_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Timestamp Difference Stats (6000 min tolerance matches) ---\n",
      "Number of linked events: 70\n",
      "Timestamp Difference (imp_click_dttm_utc vs dttm_utc):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/44kjynv56jb6jwxj228767_m0000gn/T/ipykernel_55222/3958369471.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_linked_6000min['timestamp_diff'] = (df_linked_6000min['imp_click_dttm_utc'] - df_linked_6000min['dttm_utc']).abs()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                           70\n",
       "mean     1 days 00:04:23.114285714\n",
       "std      1 days 04:15:04.476171219\n",
       "min                0 days 00:00:14\n",
       "25%                0 days 00:03:11\n",
       "50%                0 days 09:08:03\n",
       "75%                1 days 15:02:31\n",
       "max                4 days 02:45:33\n",
       "Name: timestamp_diff, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>placement_id</th>\n",
       "      <th>imp_click_dttm_utc</th>\n",
       "      <th>dttm_utc</th>\n",
       "      <th>timestamp_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>2025-04-04 21:42:19</td>\n",
       "      <td>2025-04-09 00:27:52</td>\n",
       "      <td>4 days 02:45:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>2025-04-04 22:23:34</td>\n",
       "      <td>2025-04-09 00:27:52</td>\n",
       "      <td>4 days 02:04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>2025-04-05 00:31:43</td>\n",
       "      <td>2025-04-09 00:27:52</td>\n",
       "      <td>3 days 23:56:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>2025-04-05 21:17:21</td>\n",
       "      <td>2025-04-09 00:27:52</td>\n",
       "      <td>3 days 03:10:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9317</td>\n",
       "      <td>596772</td>\n",
       "      <td>2025-04-05 21:34:48</td>\n",
       "      <td>2025-04-09 00:27:52</td>\n",
       "      <td>3 days 02:53:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    campaign_id  placement_id  imp_click_dttm_utc            dttm_utc  timestamp_diff\n",
       "30         9317        596772 2025-04-04 21:42:19 2025-04-09 00:27:52 4 days 02:45:33\n",
       "31         9317        596772 2025-04-04 22:23:34 2025-04-09 00:27:52 4 days 02:04:18\n",
       "32         9317        596772 2025-04-05 00:31:43 2025-04-09 00:27:52 3 days 23:56:09\n",
       "33         9317        596772 2025-04-05 21:17:21 2025-04-09 00:27:52 3 days 03:10:31\n",
       "34         9317        596772 2025-04-05 21:34:48 2025-04-09 00:27:52 3 days 02:53:04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure both dataframes are sorted by the timestamp you want to merge on\n",
    "df_impressions_sorted = df_impressions.sort_values('dttm_utc')\n",
    "# Use the original, unrounded timestamp for conversions here for precision\n",
    "df_conversions_sorted = df_conversions.sort_values('imp_click_dttm_utc')\n",
    "\n",
    "# Rename conversion ID columns for clarity in merge_asof\n",
    "# (Make sure you haven't already renamed these in df_conversions)\n",
    "if 'imp_click_campaign_id' in df_conversions_sorted.columns:\n",
    "    df_conversions_sorted = df_conversions_sorted.rename(columns={\n",
    "        'imp_click_campaign_id': 'campaign_id',\n",
    "        'imp_click_placement_id': 'placement_id'\n",
    "    })\n",
    "\n",
    "\n",
    "# --- Regenerate the 70 matches ---\n",
    "# Ensure sorted dataframes and renamed columns are available from previous step\n",
    "# df_impressions_sorted, df_conversions_sorted (with renamed IDs)\n",
    "\n",
    "try:\n",
    "    df_merged_asof_large_tolerance = pd.merge_asof(\n",
    "        df_conversions_sorted, # Left dataframe (conversions)\n",
    "        df_impressions_sorted, # Right dataframe (impressions)\n",
    "        left_on='imp_click_dttm_utc', # Time column from left\n",
    "        right_on='dttm_utc',         # Time column from right\n",
    "        by=['campaign_id', 'placement_id'], # Exact match columns\n",
    "        direction='nearest',         # Find nearest time match\n",
    "        tolerance=pd.Timedelta('6000 minutes') # Large tolerance\n",
    "    )\n",
    "\n",
    "    # Filter out rows where merge_asof didn't find a match within tolerance\n",
    "    df_linked_6000min = df_merged_asof_large_tolerance.dropna(subset=['dttm_utc'])\n",
    "\n",
    "    if not df_linked_6000min.empty:\n",
    "        # Calculate the absolute time difference\n",
    "        df_linked_6000min['timestamp_diff'] = (df_linked_6000min['imp_click_dttm_utc'] - df_linked_6000min['dttm_utc']).abs()\n",
    "\n",
    "        # Calculate and display statistics of the difference\n",
    "        print(\"\\n--- Timestamp Difference Stats (6000 min tolerance matches) ---\")\n",
    "        print(f\"Number of linked events: {len(df_linked_6000min)}\")\n",
    "        print(\"Timestamp Difference (imp_click_dttm_utc vs dttm_utc):\")\n",
    "        display(df_linked_6000min['timestamp_diff'].describe())\n",
    "\n",
    "        # Display a few rows showing the difference\n",
    "        display(df_linked_6000min[['campaign_id', 'placement_id', 'imp_click_dttm_utc', 'dttm_utc', 'timestamp_diff']].head())\n",
    "    else:\n",
    "        print(\"\\nNo rows linked even with 6000 min tolerance.\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"\\nMerge_asof failed. Check column names carefully: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nAn error occurred during merge_asof: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting User Columns (1 min tolerance matches) ---\n",
      "Number of linked events: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp_click_dttm_utc</th>\n",
       "      <th>dttm_utc</th>\n",
       "      <th>conv_user_agent</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>conv_dma</th>\n",
       "      <th>dma</th>\n",
       "      <th>conv_prizm_premier_code</th>\n",
       "      <th>prizm_premier_code</th>\n",
       "      <th>conv_cnxn_type</th>\n",
       "      <th>cnxn_type</th>\n",
       "      <th>conv_device_type</th>\n",
       "      <th>device_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2025-04-09 00:33:15</td>\n",
       "      <td>2025-04-09 00:33:29</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...</td>\n",
       "      <td>602</td>\n",
       "      <td>602.0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>Cable/DSL</td>\n",
       "      <td>d</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    imp_click_dttm_utc            dttm_utc                                    conv_user_agent                                         user_agent  conv_dma    dma conv_prizm_premier_code prizm_premier_code conv_cnxn_type  cnxn_type conv_device_type device_type\n",
       "76 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p\n",
       "77 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p\n",
       "78 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p\n",
       "79 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p\n",
       "80 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p\n",
       "81 2025-04-09 00:33:15 2025-04-09 00:33:29  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Mozilla/5.0 (iPhone; CPU iPhone OS 18_3_2 like...       602  602.0                      12                 25      Cable/DSL  Cable/DSL                d           p"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Regenerate the 6 matches ---\n",
    "# Ensure sorted dataframes and renamed columns are available\n",
    "# df_impressions_sorted, df_conversions_sorted (with renamed IDs)\n",
    "\n",
    "try:\n",
    "    df_merged_asof_small_tolerance = pd.merge_asof(\n",
    "        df_conversions_sorted, # Left dataframe (conversions)\n",
    "        df_impressions_sorted, # Right dataframe (impressions)\n",
    "        left_on='imp_click_dttm_utc', # Time column from left\n",
    "        right_on='dttm_utc',         # Time column from right\n",
    "        by=['campaign_id', 'placement_id'], # Exact match columns\n",
    "        direction='nearest',         # Find nearest time match\n",
    "        tolerance=pd.Timedelta('1 minute') # Small tolerance\n",
    "    )\n",
    "\n",
    "    # Filter out rows where merge_asof didn't find a match within tolerance\n",
    "    df_linked_1min = df_merged_asof_small_tolerance.dropna(subset=['dttm_utc'])\n",
    "\n",
    "    if not df_linked_1min.empty:\n",
    "        print(\"\\n--- Inspecting User Columns (1 min tolerance matches) ---\")\n",
    "        print(f\"Number of linked events: {len(df_linked_1min)}\")\n",
    "\n",
    "        # Define columns to display - adjust suffixes if needed based on your actual merge result\n",
    "        # Check df_linked_1min.columns to confirm exact names\n",
    "        cols_to_display = [\n",
    "            'imp_click_dttm_utc', 'dttm_utc', # Timestamps\n",
    "            'conv_user_agent', 'user_agent', # User Agents (check suffixes if merge added them)\n",
    "            'conv_dma', 'dma',             # DMAs (check suffixes)\n",
    "            'conv_prizm_premier_code', 'prizm_premier_code', # Prizm codes (check suffixes)\n",
    "            'conv_cnxn_type', 'cnxn_type',       # Connection types (check suffixes)\n",
    "            'conv_device_type', 'device_type'    # Device types (check suffixes)\n",
    "        ]\n",
    "\n",
    "        # Filter out columns that might not exist (e.g., if suffixes weren't added)\n",
    "        cols_exist = [col for col in cols_to_display if col in df_linked_1min.columns]\n",
    "\n",
    "        display(df_linked_1min[cols_exist])\n",
    "    else:\n",
    "        print(\"\\nNo rows linked with 1 min tolerance.\")\n",
    "\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"\\nMerge_asof failed. Check column names carefully: {e}\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nAn error occurred during merge_asof: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AuctioNN (venv)",
   "language": "python",
   "name": "auctionn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
