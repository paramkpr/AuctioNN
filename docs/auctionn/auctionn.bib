@inproceedings{cai2017real,
  title={Real-time bidding by reinforcement learning in display advertising},
  author={Cai, Han and Ren, Kan and Zhang, Weinan and Malialis, Kleanthis and Wang, Jun and Yu, Yong and Guo, Defeng},
  booktitle={Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM)},
  pages={661--670},
  year={2017},
  organization={ACM},
  doi={10.1145/3018661.3018702}
}

@inproceedings{10.1145/3514221.3526128,
author = {Wu, Wentao and Wang, Chi and Siddiqui, Tarique and Wang, Junxiong and Narasayya, Vivek and Chaudhuri, Surajit and Bernstein, Philip A.},
title = {Budget-aware Index Tuning with Reinforcement Learning},
year = {2022},
isbn = {9781450392495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514221.3526128},
doi = {10.1145/3514221.3526128},
abstract = {Index tuning aims to find the optimal index configuration for an input workload. It is a resource-intensive task since it requires making multiple expensive "what-if" calls to the query optimizer to estimate the cost of a query given an index configuration without actually building the indexes. In this paper, we study the problem of budget-aware index tuning where the number of what-if calls allowed when searching for the optimal configuration during tuning is constrained. This problem is challenging as it requires addressing the trade-off between investing what-if calls on exploring new configurations versus exploiting a known promising configuration. We formulate budget-aware index tuning as a Markov decision process, and propose a solution based on Monte Carlo tree search, a classic reinforcement learning technology. Experimental evaluation on both standard industry benchmarks and real workloads shows that our solution can significantly outperform alternative budget-aware solutions in terms of the quality of the index configuration.},
booktitle = {Proceedings of the 2022 International Conference on Management of Data},
pages = {1528â€“1541},
numpages = {14},
keywords = {budget allocation, index tuning, reinforcement learning},
location = {Philadelphia, PA, USA},
series = {SIGMOD '22}
}
@misc{liu2021bidoptimizationusingmaximum,
      title={Bid Optimization using Maximum Entropy Reinforcement Learning}, 
      author={Mengjuan Liu and Jinyu Liu and Zhengning Hu and Yuchen Ge and Xuyun Nie},
      year={2021},
      eprint={2110.05032},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.05032}, 
}


@inproceedings{cheng2016wide,
  title={Wide \& deep learning for recommender systems},
  author={Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and others},
  booktitle={Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (DLRS)},
  pages={7--10},
  year={2016},
  organization={ACM},
  doi={10.1145/2988450.2988454}
}